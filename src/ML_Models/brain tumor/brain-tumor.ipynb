{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVr1h0UrCeNf"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imghdr\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,classification_report,roc_curve,auc\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers\n",
        "from tensorflow.keras.applications import VGG16, ResNet50V2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "0NpHV2EJC7KO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to count the number of files (assumed to be images for this context) for each subdirectory in a given directory.\n",
        "# The function returns a DataFrame with these counts, indexed by a specified set name (e.g., 'train' or 'test').\n",
        "def count_files_in_subdirs(directory, set_name):\n",
        "    # Initialize an empty dictionary to hold the count of files for each subdirectory.\n",
        "    counts = {}\n",
        "\n",
        "    # Iterate over each item in the given directory.\n",
        "    for item in os.listdir(directory):\n",
        "        # Construct the full path to the item.\n",
        "        item_path = os.path.join(directory, item)\n",
        "\n",
        "        # Check if the item is a directory.\n",
        "        if os.path.isdir(item_path):\n",
        "            # Count the number of files in the subdirectory and add it to the dictionary.\n",
        "            counts[item] = len(os.listdir(item_path))\n",
        "\n",
        "    # Convert the counts dictionary to a DataFrame for easy viewing and analysis.\n",
        "    # The index of the DataFrame is set to the provided set name.\n",
        "    df = pd.DataFrame(counts, index=[set_name])\n",
        "    return df\n",
        "\n",
        "# Paths to the training and testing directories.\n",
        "train_dir = '/kaggle/input/brain-tumor-mri-dataset/Training'\n",
        "test_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing'\n",
        "\n",
        "# Count the files in the subdirectories of the training directory and print the result.\n",
        "train_count = count_files_in_subdirs(train_dir, 'train')\n",
        "print(train_count)\n",
        "\n",
        "# Count the files in the subdirectories of the testing directory and print the result.\n",
        "test_count = count_files_in_subdirs(test_dir, 'test')\n",
        "print(test_count)"
      ],
      "metadata": {
        "id": "k3Rg6RTPC_79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count.transpose().plot(kind='bar')"
      ],
      "metadata": {
        "id": "9MquZ_9wDC9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_count.transpose().plot(kind='bar')"
      ],
      "metadata": {
        "id": "rCznmtzuDHqJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "diseases = os.listdir(train_dir)  # List all disease folders in the training directory\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, disease in enumerate(diseases[:4], 1):  # Limit to 4 diseases for visualization\n",
        "    folder = os.path.join(train_dir, disease)\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    # Ensure folder has enough images\n",
        "    if len(files) > 42:\n",
        "        img_path = os.path.join(folder, files[42])  # Access the 42nd image\n",
        "        img = plt.imread(img_path)\n",
        "        plt.subplot(2, 2, i)  # Create a 2x2 grid for visualization\n",
        "        plt.imshow(img,cmap='gray')\n",
        "        plt.title(f'Disease: {disease}')\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        print(f\"Not enough images in {disease} folder.\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "QYqBLEF0DJwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_img_from_directory(directory,set_name,num_images=9):\n",
        "    img_filenames=os.listdir(directory)\n",
        "    if len(img_filenames)<num_images:\n",
        "        print(f\"only found {len(img_filenames)} in directory {directory} display them all\")\n",
        "        num_images=len(img_filenmaes)\n",
        "    selected_img=random.sample(img_filenames,num_images)\n",
        "    fig,axis=plt.subplots(3,3,figsize=(5,5))\n",
        "    axis=axis.ravel()\n",
        "    for i,img_id in enumerate(selected_img):\n",
        "        img_path=os.path.join(directory,img_id)\n",
        "        img=load_img(img_path)\n",
        "        axis[i].imshow(img)\n",
        "        axis[i].set_title(f'Image--{set_name}')\n",
        "        axis[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "nISykdC_DP0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/brain-tumor-mri-dataset/Training/glioma'\n",
        "plot_img_from_directory(normal_dir_path,set_name='giloma')"
      ],
      "metadata": {
        "id": "v4vWtxbQDRy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/brain-tumor-mri-dataset/Training/meningioma'\n",
        "plot_img_from_directory(normal_dir_path,set_name='meningioma')"
      ],
      "metadata": {
        "id": "43zSgonGDTt7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/brain-tumor-mri-dataset/Training/notumor'\n",
        "plot_img_from_directory(normal_dir_path,set_name='notumor')"
      ],
      "metadata": {
        "id": "lwmz9G68DVbV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/brain-tumor-mri-dataset/Training/pituitary'\n",
        "plot_img_from_directory(normal_dir_path,set_name='pituitary')"
      ],
      "metadata": {
        "id": "_AICirENDbZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='/kaggle/input/brain-tumor-mri-dataset/Training/glioma/Tr-glTr_0007.jpg'\n",
        "import cv2\n",
        "img=plt.imread(img_path)\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "nD0GauHvDdkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_count.transpose().plot(kind='bar')"
      ],
      "metadata": {
        "id": "NGDr8FL9Dfbp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width=512\n",
        "img_height=512\n",
        "batch_size=32\n",
        "num_classes=4"
      ],
      "metadata": {
        "id": "O2JLCFiLDhIK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir='/kaggle/input/brain-tumor-mri-dataset/Training'\n",
        "test_data_dir='/kaggle/input/brain-tumor-mri-dataset/Testing'"
      ],
      "metadata": {
        "id": "414bISTxDijp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator=ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "\n",
        "train_generator=data_generator.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "validation_generator=data_generator.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        ")\n",
        "\n",
        "test_generator=data_generator.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "BlYs0fuvDmtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_indices=train_generator.class_indices\n",
        "print(train_data_indices)\n",
        "test_data_indices=test_generator.class_indices\n",
        "print(test_data_indices)\n",
        "validation_data_indices=validation_generator.class_indices\n",
        "print(validation_data_indices)"
      ],
      "metadata": {
        "id": "f1CKPAfoDozq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(512,512,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(4,activation='softmax'))"
      ],
      "metadata": {
        "id": "vK3i3t76Drlh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "nZVwuO2UDuY6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "j7fzP9f8Dv1M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model,show_shapes=True,show_layer_names=True)"
      ],
      "metadata": {
        "id": "9RDb3Fv_Dyx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback for early stopping\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)"
      ],
      "metadata": {
        "id": "6WL_eCNOD1p6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Switch to a different metric if needed\n",
        "    factor=0.2,\n",
        "    patience=6,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")"
      ],
      "metadata": {
        "id": "5ilMJPXJD3O5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[earlystop,reduce_lr]"
      ],
      "metadata": {
        "id": "2ank8GkSD4ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "ZeVLqQEGD5pV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    # Plot training and validation accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "TX8eXeF0D_Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "QAS-XA6hEHwJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_classes=test_generator.classes\n",
        "predicted_classes=np.argmax(model.predict(test_generator,steps=int(np.ceil(test_generator.samples/test_generator.batch_size))),axis=1)\n",
        "class_label=list(test_generator.class_indices.keys())\n",
        "\n",
        "cm=confusion_matrix(true_classes,predicted_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_label, yticklabels=class_label)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ER7iB_lZEJ1j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the classification report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_label)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "YDG3KCg5EMmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_data_dir = '/kaggle/input/brain-tumor-mri-dataset/Training'\n",
        "test_data_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing'\n",
        "\n",
        "# Set parameters\n",
        "img_width, img_height = 224, 224  # Adjust to 224x224 for pretrained models like VGG16\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "num_classes = 5\n",
        "\n",
        "# Data augmentation and preprocessing for training\n",
        "data_generator = ImageDataGenerator(\n",
        "    rescale=1./255.,  # Consistent scaling\n",
        "    rotation_range=10,\n",
        "    zoom_range=0.2,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest',\n",
        "    validation_split=0.2  # Fix: Set validation split here\n",
        ")\n",
        "\n",
        "# Data preprocessing for testing (no augmentation)\n",
        "test_preprocessor = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "# Training data generator\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    subset='training',  # Ensure validation split is defined\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Validation data generator\n",
        "val_generator = data_generator.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb',\n",
        "    subset='validation'  # Ensure correct usage of subset\n",
        ")\n",
        "\n",
        "# Testing data generator (no augmentation)\n",
        "test_generator = test_preprocessor.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width, img_height),\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    color_mode='rgb'\n",
        ")\n"
      ],
      "metadata": {
        "id": "wQcb-IqXEQVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback for early stopping\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# Callback to reduce learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=6,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)"
      ],
      "metadata": {
        "id": "rY8nra4cESEA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[earlystop,reduce_lr]"
      ],
      "metadata": {
        "id": "kXVjV0x3ETfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(224,224,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(4,activation='softmax'))"
      ],
      "metadata": {
        "id": "UdUCxYw0EVBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "em5PUJKCEWwR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "8MZa8CBuEYW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "IjDUhnB5EZpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the ResNet50V2 model with input shape\n",
        "def Create_ResNet50V2_Model():\n",
        "    input_layer = Input(shape=(224, 224, 3))\n",
        "\n",
        "    resnet_base = ResNet50V2(input_shape=(224, 224, 3),\n",
        "                             include_top=False,\n",
        "                             weights='imagenet')\n",
        "\n",
        "    resnet_base.trainable = False  # Freeze pre-trained layers\n",
        "\n",
        "    x = resnet_base(input_layer)\n",
        "    x = GlobalAveragePooling2D()(x)  # Use GAP instead of Flatten\n",
        "    x = Dropout(0.25)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dense(64, activation='relu', kernel_regularizer=l2(0.001), kernel_initializer='he_uniform')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    output_layer = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate and summarize the model\n",
        "model = Create_ResNet50V2_Model()\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "pA37Wn-REcY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "gKWF2ZwbEe5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "ebjpuoMwEgkL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('best_model1.h5')"
      ],
      "metadata": {
        "id": "D2N3HdYmEiy6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Corrected disease classes\n",
        "disease_Classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Assuming test_generator and model are already defined\n",
        "batch_size = test_generator.batch_size\n",
        "\n",
        "# Selecting a random batch from the test generator\n",
        "Random_batch = np.random.randint(0, len(test_generator))\n",
        "\n",
        "# Selecting random image indices from the batch (ensuring index is within range)\n",
        "Random_Img_Index = np.random.randint(0, min(batch_size, len(test_generator[Random_batch][0])), 6)\n",
        "\n",
        "# Setting up the plot\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 10),\n",
        "                         subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Fetching the random image and its label\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]])\n",
        "\n",
        "    # Making a prediction using the model\n",
        "    Model_Prediction = np.argmax(model.predict(tf.expand_dims(Random_Img, axis=0), verbose=0), axis=1)[0]\n",
        "\n",
        "    # Set title color based on prediction correctness\n",
        "    color = \"green\" if disease_Classes[Random_Img_Label] == disease_Classes[Model_Prediction] else \"red\"\n",
        "\n",
        "    ax.imshow(Random_Img)  # Assuming images are RGB, remove cmap='gray' if not grayscale\n",
        "    ax.set_title(f\"True: {disease_Classes[Random_Img_Label]}\\nPredicted: {disease_Classes[Model_Prediction]}\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "yt9_HQPoElub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model('best_model1.h5')  # Replace with your saved model path\n",
        "\n",
        "# List of class names\n",
        "Emotion_Classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "\n",
        "# Assuming test_generator and model are already defined\n",
        "batch_size = test_generator.batch_size\n",
        "\n",
        "# Selecting a random batch from the test generator\n",
        "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
        "\n",
        "# Selecting random image indices from the batch\n",
        "Random_Img_Index = np.random.randint(0, batch_size, 10)\n",
        "\n",
        "# Setting up the plot\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 5),\n",
        "                         subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Fetching the random image and its label\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]], axis=0)\n",
        "\n",
        "    # Making a prediction using the model\n",
        "    Model_Prediction = np.argmax(model.predict(tf.expand_dims(Random_Img, axis=0), verbose=0), axis=1)[0]\n",
        "\n",
        "    ax.imshow(Random_Img.squeeze(), cmap='gray')  # Assuming the images are grayscale\n",
        "    # Setting the title with true and predicted labels, colored based on correctness\n",
        "    color = \"green\" if disease_Classes[Random_Img_Label] == disease_Classes[Model_Prediction] else \"red\"\n",
        "    ax.set_title(f\"True: {disease_Classes[Random_Img_Label]}\\nPredicted: {disease_Classes[Model_Prediction]}\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "vYbsUuOMEpPz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from keras.models import load_model\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model('best_model1.h5')  # Replace with your saved model path\n",
        "\n",
        "# Define class names\n",
        "disease_Classes = ['glioma', 'meningioma', 'notumor', 'pituitary']\n",
        "\n",
        "# Load test data using ImageDataGenerator\n",
        "test_dir = '/kaggle/input/brain-tumor-mri-dataset/Testing'  # Update your test data path\n",
        "img_size = (224, 224)\n",
        "batch_size = 32\n",
        "\n",
        "# Preprocessing the test data\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_dir,\n",
        "    target_size=img_size,\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    shuffle=False  # Do not shuffle for correct evaluation\n",
        ")\n",
        "\n",
        "# Step 1: Evaluate the model on the entire test set\n",
        "test_loss, test_accuracy = model.evaluate(test_generator, verbose=1)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "\n",
        "# Step 2: Predict on the entire test set\n",
        "predictions = model.predict(test_generator, verbose=1)\n",
        "\n",
        "# Convert predictions to class indices\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get the true labels from the generator\n",
        "true_classes = test_generator.classes\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report:\\n\")\n",
        "report = classification_report(true_classes, predicted_classes, target_names=disease_Classes)\n",
        "print(report)\n",
        "\n",
        "# Step 3: Plot confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=disease_Classes, yticklabels=disease_Classes)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Step 4: Visualize random test images with predictions\n",
        "num_samples = 6  # Number of images to visualize\n",
        "random_indices = np.random.choice(len(test_generator.filenames), num_samples, replace=False)\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "\n",
        "for i, idx in enumerate(random_indices):\n",
        "    img_path = test_generator.filepaths[idx]\n",
        "    img = tf.keras.preprocessing.image.load_img(img_path, target_size=img_size)\n",
        "    img_array = tf.keras.preprocessing.image.img_to_array(img) / 255.0  # Normalize\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    pred = np.argmax(model.predict(img_array), axis=1)[0]\n",
        "    true_label = test_generator.classes[idx]\n",
        "\n",
        "    plt.subplot(2, 3, i + 1)\n",
        "    plt.imshow(img)\n",
        "    color = \"green\" if pred == true_label else \"red\"\n",
        "    plt.title(f\"True: {disease_Classes[true_label]}\\nPred: {disease_Classes[pred]}\", color=color)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "to2YdWe7EsY_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}