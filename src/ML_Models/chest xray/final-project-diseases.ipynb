{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTHfq8DOFZ7a"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imghdr\n",
        "import tensorflow as tf\n",
        "from PIL import Image\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.metrics import confusion_matrix,classification_report,roc_curve,auc\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import pandas as pd\n",
        "\n",
        "from tensorflow.keras import layers, models, regularizers, optimizers\n",
        "from tensorflow.keras.applications import VGG16, ResNet50V2\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard, CSVLogger\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout, Flatten, Dense, Activation, GlobalAveragePooling2D\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam, Adamax\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.utils import plot_model"
      ],
      "metadata": {
        "id": "_WlG6NasFfxq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a function to count the number of files (assumed to be images for this context) for each subdirectory in a given directory.\n",
        "# The function returns a DataFrame with these counts, indexed by a specified set name (e.g., 'train' or 'test').\n",
        "def count_files_in_subdirs(directory, set_name):\n",
        "    # Initialize an empty dictionary to hold the count of files for each subdirectory.\n",
        "    counts = {}\n",
        "\n",
        "    # Iterate over each item in the given directory.\n",
        "    for item in os.listdir(directory):\n",
        "        # Construct the full path to the item.\n",
        "        item_path = os.path.join(directory, item)\n",
        "\n",
        "        # Check if the item is a directory.\n",
        "        if os.path.isdir(item_path):\n",
        "            # Count the number of files in the subdirectory and add it to the dictionary.\n",
        "            counts[item] = len(os.listdir(item_path))\n",
        "\n",
        "    # Convert the counts dictionary to a DataFrame for easy viewing and analysis.\n",
        "    # The index of the DataFrame is set to the provided set name.\n",
        "    df = pd.DataFrame(counts, index=[set_name])\n",
        "    return df\n",
        "\n",
        "# Paths to the training and testing directories.\n",
        "train_dir = '/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train'\n",
        "test_dir = '/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/test'\n",
        "\n",
        "# Count the files in the subdirectories of the training directory and print the result.\n",
        "train_count = count_files_in_subdirs(train_dir, 'train')\n",
        "print(train_count)\n",
        "\n",
        "# Count the files in the subdirectories of the testing directory and print the result.\n",
        "test_count = count_files_in_subdirs(test_dir, 'test')\n",
        "print(test_count)"
      ],
      "metadata": {
        "id": "3SCJE-f_F2fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_count.transpose().plot(kind='bar')"
      ],
      "metadata": {
        "id": "oJ2PSRGSF8JM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "diseases = os.listdir(train_dir)  # List all disease folders in the training directory\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "for i, disease in enumerate(diseases[:4], 1):  # Limit to 4 diseases for visualization\n",
        "    folder = os.path.join(train_dir, disease)\n",
        "    files = os.listdir(folder)\n",
        "\n",
        "    # Ensure folder has enough images\n",
        "    if len(files) > 42:\n",
        "        img_path = os.path.join(folder, files[42])  # Access the 42nd image\n",
        "        img = plt.imread(img_path)\n",
        "        plt.subplot(2, 2, i)  # Create a 2x2 grid for visualization\n",
        "        plt.imshow(img,cmap='gray')\n",
        "        plt.title(f'Disease: {disease}')\n",
        "        plt.axis('off')\n",
        "    else:\n",
        "        print(f\"Not enough images in {disease} folder.\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "fcadBGXHF-uP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_img_from_directory(directory,set_name,num_images=9):\n",
        "    img_filenames=os.listdir(directory)\n",
        "    if len(img_filenames)<num_images:\n",
        "        print(f\"only found {len(img_filenames)} in directory {directory} display them all\")\n",
        "        num_images=len(img_filenmaes)\n",
        "    selected_img=random.sample(img_filenames,num_images)\n",
        "    fig,axis=plt.subplots(3,3,figsize=(5,5))\n",
        "    axis=axis.ravel()\n",
        "    for i,img_id in enumerate(selected_img):\n",
        "        img_path=os.path.join(directory,img_id)\n",
        "        img=load_img(img_path)\n",
        "        axis[i].imshow(img)\n",
        "        axis[i].set_title(f'Image--{set_name}')\n",
        "        axis[i].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        ""
      ],
      "metadata": {
        "id": "WtIvrzDUGAck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Normal'\n",
        "plot_img_from_directory(normal_dir_path,set_name='normal')"
      ],
      "metadata": {
        "id": "84dp7ryfGFmV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Tuberculosis'\n",
        "plot_img_from_directory(normal_dir_path,set_name='Tuberculosis')"
      ],
      "metadata": {
        "id": "3FS645rBGH3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_dir_path='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Viral Pneumonia'\n",
        "plot_img_from_directory(normal_dir_path,set_name='Pneumonia')"
      ],
      "metadata": {
        "id": "bqZlJPvdGJ6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_path='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train/Bacterial Pneumonia/158.jpeg'\n",
        "import cv2\n",
        "img=plt.imread(img_path)\n",
        "print(img.shape)"
      ],
      "metadata": {
        "id": "wpmV4vZtGMTh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_width=256\n",
        "img_height=256\n",
        "batch_size=32\n",
        "num_classes=5"
      ],
      "metadata": {
        "id": "XnO4iGZLGOQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train'\n",
        "test_data_dir='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/test'\n",
        "val_data_dir='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/val'"
      ],
      "metadata": {
        "id": "BRu30sfoGPtg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_generator=ImageDataGenerator(rescale=1./255,validation_split=0.2)\n",
        "\n",
        "train_generator=data_generator.flow_from_directory(\n",
        "    train_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='training',\n",
        ")\n",
        "validation_generator=data_generator.flow_from_directory(\n",
        "    val_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "    subset='validation',\n",
        ")\n",
        "\n",
        "test_generator=data_generator.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=(img_width,img_height),\n",
        "    color_mode='grayscale',\n",
        "    batch_size=batch_size,\n",
        "    class_mode='categorical',\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "HifdmV2yGVUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_generator\n"
      ],
      "metadata": {
        "id": "Zu07NSZfGX42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# aceess the indices\n",
        "train_data_indices=train_generator.class_indices\n",
        "print(train_data_indices)\n",
        "test_data_indices=test_generator.class_indices\n",
        "print(test_data_indices)\n",
        "validation_data_indices=validation_generator.class_indices\n",
        "print(validation_data_indices)"
      ],
      "metadata": {
        "id": "YIIHTqUkGZqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(256,256,1)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(5,activation='softmax'))"
      ],
      "metadata": {
        "id": "D4wi46XPF5Z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "YSbbmRK1GiQF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "JWx39WgfGjxw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_model(model,show_shapes=True,show_layer_names=True)"
      ],
      "metadata": {
        "id": "1DraxQBQGlxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Callback for early stopping\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)"
      ],
      "metadata": {
        "id": "DghRxDQVGpHG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',  # Switch to a different metric if needed\n",
        "    factor=0.2,\n",
        "    patience=6,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")\n"
      ],
      "metadata": {
        "id": "qow8MMNjGqqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[earlystop,reduce_lr]"
      ],
      "metadata": {
        "id": "SjnFO0acGsOq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "sQv0CW0VGtqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    # Plot training and validation accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "S3qA4ZWzGwKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "PblcUBgMGyZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_classes=test_generator.classes\n",
        "predicted_classes=np.argmax(model.predict(test_generator,steps=int(np.ceil(test_generator.samples/test_generator.batch_size))),axis=1)\n",
        "class_label=list(test_generator.class_indices.keys())\n",
        "\n",
        "cm=confusion_matrix(true_classes,predicted_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_label, yticklabels=class_label)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lCK3bGvIG0RT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing the classification report\n",
        "report = classification_report(true_classes, predicted_classes, target_names=class_label)\n",
        "print(\"Classification Report:\\n\", report)"
      ],
      "metadata": {
        "id": "SlCDyBbjG2eu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion classes for the dataset\n",
        "Emotion_Classes = ['Bacterial Pneumonia', 'Corona Virus Disease', 'Normal', 'Tuberculosis', 'Viral Pneumonia']\n",
        "\n",
        "# Assuming test_generator and model are already defined\n",
        "batch_size = test_generator.batch_size\n",
        "\n",
        "# Selecting a random batch from the test generator\n",
        "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
        "\n",
        "# Selecting random image indices from the batch\n",
        "Random_Img_Index = np.random.randint(0, batch_size, 10)\n",
        "\n",
        "# Setting up the plot\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 5),\n",
        "                         subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Fetching the random image and its label\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]], axis=0)\n",
        "\n",
        "    # Making a prediction using the model\n",
        "    Model_Prediction = np.argmax(model.predict(tf.expand_dims(Random_Img, axis=0), verbose=0), axis=1)[0]\n",
        "\n",
        "    # Displaying the image\n",
        "    ax.imshow(Random_Img.squeeze(), cmap='gray')  # Assuming the images are grayscale\n",
        "    # Setting the title with true and predicted labels, colored based on correctness\n",
        "    color = \"green\" if Emotion_Classes[Random_Img_Label] == Emotion_Classes[Model_Prediction] else \"red\"\n",
        "    ax.set_title(f\"True: {Emotion_Classes[Random_Img_Label]}\\nPredicted: {Emotion_Classes[Model_Prediction]}\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "9m6dVXliG5Ee"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_dir = '/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/train'\n",
        "test_data_dir = '/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/test'\n",
        "val_data_dir='/kaggle/input/lungs-disease-dataset-4-types/Lung Disease Dataset/val'\n",
        "\n",
        "\n",
        "\n",
        "# Set some parameters\n",
        "img_width, img_height = 224, 224  # Size of images\n",
        "batch_size = 64\n",
        "epochs = 10\n",
        "num_classes = 5\n",
        "data_generator = ImageDataGenerator(\n",
        "                                rescale = 1 / 255.,\n",
        "                                rotation_range=10,\n",
        "                                zoom_range=0.2,\n",
        "                                width_shift_range=0.1,\n",
        "                                height_shift_range=0.1,\n",
        "                                horizontal_flip=True,\n",
        "                                fill_mode='nearest',\n",
        "                                # validation_split=0.2\n",
        "                                )\n",
        "\n",
        "test_preprocessor = ImageDataGenerator(\n",
        "    rescale = 1 / 255.,\n",
        ")\n",
        "\n",
        "\n",
        "train_generator = data_generator.flow_from_directory(\n",
        "                                train_data_dir,\n",
        "                                target_size=(img_width, img_height),\n",
        "                                batch_size=batch_size,\n",
        "                                class_mode='categorical',\n",
        "                                color_mode='rgb',\n",
        "                                subset='training',\n",
        "                                shuffle = True)\n",
        "\n",
        "val_generator = data_generator.flow_from_directory(\n",
        "                                val_data_dir,\n",
        "                                target_size=(img_width, img_height),\n",
        "                                batch_size=batch_size,\n",
        "                                class_mode='categorical',\n",
        "                                color_mode='rgb',\n",
        "                                shuffle = True)\n",
        "\n",
        "test_generator = test_preprocessor.flow_from_directory(\n",
        "                                test_data_dir,\n",
        "                                target_size=(img_width, img_height),\n",
        "                                batch_size=batch_size,\n",
        "                                class_mode='categorical',\n",
        "                                color_mode='rgb',)\n",
        "                                # subset='validation')"
      ],
      "metadata": {
        "id": "nGX38s1PG9nt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Callback for early stopping\n",
        "earlystop = EarlyStopping(monitor='val_loss',\n",
        "                          min_delta=0,\n",
        "                          patience=3,\n",
        "                          verbose=1,\n",
        "                          restore_best_weights=True)\n",
        "\n",
        "# Callback to reduce learning rate\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
        "                              factor=0.2,\n",
        "                              patience=6,\n",
        "                              verbose=1,\n",
        "                              min_delta=0.0001)"
      ],
      "metadata": {
        "id": "quh8VnWVHA6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[earlystop,reduce_lr]"
      ],
      "metadata": {
        "id": "NaMBat7JHCnK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu',input_shape=(224,224,3)))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(64,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Conv2D(128,kernel_size=(3,3),padding='valid',activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2),padding='valid'))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(64,activation='relu'))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(5,activation='softmax'))"
      ],
      "metadata": {
        "id": "I-Cgk8wlHEuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "OagrqySYHGqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "_UyW6mgVHIzr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "QUH5ARlsHLHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dropout, BatchNormalization, Flatten, Dense, Input\n",
        "from tensorflow.keras.applications import ResNet50V2\n",
        "from keras.regularizers import l2\n",
        "\n",
        "# Define the ResNet50V2 model with input shape\n",
        "def Create_ResNet50V2_Model():\n",
        "    input_layer = Input(shape=(224, 224, 3))  # Define the input layer explicitly\n",
        "    resnet_layer = ResNet50V2(input_shape=(224, 224, 3),\n",
        "                               include_top=False,\n",
        "                               weights='imagenet')(input_layer)  # Include ResNet50V2 as a layer\n",
        "\n",
        "    # Add custom layers after ResNet50V2\n",
        "    x = Dropout(0.25)(resnet_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    # x = Dense(64, activation='relu')(x)\n",
        "    # x=Dropout(0.1)(x)\n",
        "    output_layer = Dense(5, activation='softmax')(x)\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Instantiate and summarize the model\n",
        "model = Create_ResNet50V2_Model()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "qWbayGNWHPac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model.compile(optimizer='Adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "z0Nwns8kHRy0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=100,\n",
        "    validation_data=val_generator,\n",
        "    callbacks=callbacks)"
      ],
      "metadata": {
        "id": "4pmYKtu2HTe9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disease_Classes = ['Bacterial Pneumonia', 'Corona Virus Disease', 'Normal', 'Tuberculosis', 'Viral Pneumonia']\n",
        "\n",
        "# Assuming test_generator and model are already defined\n",
        "batch_size = test_generator.batch_size\n",
        "\n",
        "# Selecting a random batch from the test generator\n",
        "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
        "\n",
        "# Selecting random image indices from the batch\n",
        "Random_Img_Index = np.random.randint(0, batch_size, 10)\n",
        "\n",
        "# Setting up the plot\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 5),\n",
        "                         subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Fetching the random image and its label\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]], axis=0)\n",
        "\n",
        "    # Making a prediction using the model\n",
        "    Model_Prediction = np.argmax(model.predict(tf.expand_dims(Random_Img, axis=0), verbose=0), axis=1)[0]\n",
        "\n",
        "    ax.imshow(Random_Img.squeeze(), cmap='gray')  # Assuming the images are grayscale\n",
        "    # Setting the title with true and predicted labels, colored based on correctness\n",
        "    color = \"green\" if disease_Classes[Random_Img_Label] == disease_Classes[Model_Prediction] else \"red\"\n",
        "    ax.set_title(f\"True: {disease_Classes[Random_Img_Label]}\\nPredicted: {disease_Classes[Model_Prediction]}\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "a66n6zt-HVzd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    # Plot training and validation accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "rS6aR5BfHYfV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_classes=test_generator.classes\n",
        "predicted_classes=np.argmax(model.predict(test_generator,steps=int(np.ceil(test_generator.samples/test_generator.batch_size))),axis=1)\n",
        "class_label=list(test_generator.class_indices.keys())\n",
        "\n",
        "cm=confusion_matrix(true_classes,predicted_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_label, yticklabels=class_label)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1z5e2u-pHaiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Model\n",
        "\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "def Create_ResNet50V2_Model():\n",
        "    input_layer = Input(shape=(224, 224, 3))  # Define the input layer explicitly\n",
        "    resnet_layer = ResNet50V2(input_shape=(224, 224, 3),\n",
        "                               include_top=False,\n",
        "                               weights='imagenet')(input_layer)  # Include ResNet50V2 as a layer\n",
        "\n",
        "    # Add custom layers after ResNet50V2\n",
        "    x = Dropout(0.25)(resnet_layer)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Flatten()(x)\n",
        "    x = Dense(64, activation='relu')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.1)(x)\n",
        "    output_layer = Dense(5, activation='softmax')(x)  # 5 classes for multiclass classification\n",
        "\n",
        "    # Create the model\n",
        "    model = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "    return model\n",
        "\n",
        "# Initialize the model\n",
        "model = Create_ResNet50V2_Model()\n",
        "\n",
        "# Freeze the ResNet50V2 layers initially (feature extraction phase)\n",
        "for layer in model.layers[1].layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model with a lower learning rate (for feature extraction)\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model on the custom layers only (initial training phase)\n",
        "history = model.fit(\n",
        "    train_generator,  # Assuming you have a data generator for training\n",
        "    epochs=10,        # Train for a few epochs (e.g., 10 epochs)\n",
        "    validation_data=val_generator,  # Validation data\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y2f9dUA1HeCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "disease_Classes = ['Bacterial Pneumonia', 'Corona Virus Disease', 'Normal', 'Tuberculosis', 'Viral Pneumonia']\n",
        "\n",
        "# Assuming test_generator and model are already defined\n",
        "batch_size = test_generator.batch_size\n",
        "\n",
        "# Selecting a random batch from the test generator\n",
        "Random_batch = np.random.randint(0, len(test_generator) - 1)\n",
        "\n",
        "# Selecting random image indices from the batch\n",
        "Random_Img_Index = np.random.randint(0, batch_size, 10)\n",
        "\n",
        "# Setting up the plot\n",
        "fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(10, 10),\n",
        "                         subplot_kw={'xticks': [], 'yticks': []})\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Fetching the random image and its label\n",
        "    Random_Img = test_generator[Random_batch][0][Random_Img_Index[i]]\n",
        "    Random_Img_Label = np.argmax(test_generator[Random_batch][1][Random_Img_Index[i]], axis=0)\n",
        "\n",
        "    # Making a prediction using the model\n",
        "    Model_Prediction = np.argmax(model.predict(tf.expand_dims(Random_Img, axis=0), verbose=0), axis=1)[0]\n",
        "\n",
        "    # Set title color based on prediction correctness\n",
        "    color = \"green\" if disease_Classes[Random_Img_Label] == disease_Classes[Model_Prediction] else \"red\"\n",
        "\n",
        "    ax.imshow(Random_Img.squeeze(), cmap='gray')  # Assuming the images are grayscale\n",
        "    ax.set_title(f\"True: {disease_Classes[Random_Img_Label]}\\nPredicted: {disease_Classes[Model_Prediction]}\", color=color)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "DT7ik5R8Hgkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "\n",
        "    acc = history.history['accuracy']\n",
        "    val_acc = history.history['val_accuracy']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "\n",
        "    epochs_range = range(len(acc))\n",
        "\n",
        "    plt.figure(figsize=(20, 5))\n",
        "\n",
        "    # Plot training and validation accuracy\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "    plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "\n",
        "    # Plot training and validation loss\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(epochs_range, loss, label='Training Loss')\n",
        "    plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "jjdvafBhHkRJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "Scl3-svrHmXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_classes=test_generator.classes\n",
        "predicted_classes=np.argmax(model.predict(test_generator,steps=int(np.ceil(test_generator.samples/test_generator.batch_size))),axis=1)\n",
        "class_label=list(test_generator.class_indices.keys())\n",
        "\n",
        "cm=confusion_matrix(true_classes,predicted_classes)\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_label, yticklabels=class_label)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True label')\n",
        "plt.xlabel('Predicted label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Zes_KYjbHn4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('best_model.h5')"
      ],
      "metadata": {
        "id": "s8QASvm8HqC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "# Load your trained model\n",
        "model = load_model('best_model.h5')  # Replace with your saved model path\n",
        "\n",
        "# List of class names\n",
        "Emotion_Classes = ['Bacterial Pneumonia', 'Corona Virus Disease', 'Normal', 'Tuberculosis', 'Viral Pneumonia']\n",
        "\n",
        "# Define a prediction function\n",
        "def predict_condition(image):\n",
        "    # Resize the image to match the model's expected input size\n",
        "    image = cv2.resize(image, (224, 224))  # Adjust (224, 224) if your model expects a different size\n",
        "    image = np.expand_dims(image, axis=0)  # Add batch dimension\n",
        "    image = image / 255.0  # Normalize the image if your model expects it\n",
        "\n",
        "    # Predict the class\n",
        "    prediction = model.predict(image)\n",
        "    predicted_class = np.argmax(prediction)\n",
        "\n",
        "    return f\"Predicted Condition: {Emotion_Classes[predicted_class]}\"\n",
        "\n",
        "# Define Gradio interface\n",
        "interface = gr.Interface(\n",
        "    fn=predict_condition,\n",
        "    inputs=gr.Image(),  # No shape argument needed here\n",
        "    outputs=gr.Text(),\n",
        "    title=\"Disease Classification from Chest X-Ray\",\n",
        "    description=\"Upload a chest X-ray image, and the model will predict the disease category.\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "id": "0XKYj2vdHs0M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}